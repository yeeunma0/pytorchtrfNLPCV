{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예제 4.3 가중치 초기화 함수(1)\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(1,2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(2,1)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.layer[0].weight)\n",
    "        self.layer[0].bias.data.fill_(0.01)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        self.fc.bias.data.fill_(0.01)\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply : Linear(in_features=1, out_features=2, bias=True)\n",
      "Apply : Sigmoid()\n",
      "Apply : Sequential(\n",
      "  (0): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (1): Sigmoid()\n",
      ")\n",
      "Apply : Linear(in_features=2, out_features=1, bias=True)\n",
      "Apply : Net(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=2, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#예제 4.4 가중치 초기화 함수(2)\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(1,2),\n",
    "            nn.Sigmoid()            \n",
    "        )\n",
    "        self.fc = nn.Linear(2,1)\n",
    "        self.apply(self._init_weights) #Net 클래스의 모든 모듈에 _init_weights 함수를 재귀적으로 적용한다.\n",
    "        #여기서 모듈은 nn.Module을 상속받은 모든 요소를 의미하며, 이는 개별 레이어 뿐만 아니라 시퀀셜 자체와 전체 클래스 자체도 포함된다.\n",
    "        #따라서 각 모듈이 _init_weights 함수에 의해 방문될 때마다 해당 모듈에 대한 정보가 출력된다.\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.constant_(module.bias, 0.01) #상수초기화 함수\n",
    "        print(f\"Apply : {module}\")\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb3bd0dfd6e43e1a6070432f753135e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81548eef1dcf451d91cfd735d67446ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd71e352a6e34216af0a2bff5050986f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614c0e4a044a43b488b39caf3394edfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd581f6b4164e1ab9b042303727c128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src : Those who can imagine anything can create the impossible.\n",
      "dst : those who can imagine sees anything that can create the impossible impossible.\n",
      "------------------\n",
      "src : We can only see a chort diatance ahead, but we can see plenty there that needs to be done.\n",
      "dst : well we can only still see through a chort the diatance ahead, but we probably can see plenty ahead there so that needs to be done.\n",
      "------------------\n",
      "src : If a machine is expected to be infaillible, it cannot also be intelligent.\n",
      "dst : imagine if a machine is expected to be mentally infaillible, but it also cannot automatically also be genetically intelligent.\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "#예제 4.10 단어 삽입\n",
    "\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "texts = [\"Those who can imagine anything can create the impossible.\",\n",
    "         \"We can only see a chort diatance ahead, but we can see plenty there that needs to be done.\",\n",
    "         \"If a machine is expected to be infaillible, it cannot also be intelligent.\"]\n",
    "         \n",
    "aug = naw.ContextualWordEmbsAug(model_path = \"bert-base-uncased\", action = \"insert\")\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f\"src : {text}\")\n",
    "    print(f\"dst : {augmented}\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src : Those who can imagine anything can create the impossible.\n",
      "dst : Those who could imagine anything cannot create the impossible.\n",
      "------------------\n",
      "src : We can only see a short diatance ahead, but we can see plenty there that needs to be done.\n",
      "dst : We cannot only see a short diatance ahead, but we could see plenty there that needs to be done.\n",
      "------------------\n",
      "src : If a machine is expected to be infaillible, it cannot also be intelligent.\n",
      "dst : If a machine is expected to be infaillible, it could also be intelligent.\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "texts = [\"Those who can imagine anything can create the impossible.\",\n",
    "         \"We can only see a short diatance ahead, but we can see plenty there that needs to be done.\",\n",
    "         \"If a machine is expected to be infaillible, it cannot also be intelligent.\"]\n",
    "reserved_tokens = [[\"can\",\"can't\",\"cannot\",\"could\"],]        \n",
    " \n",
    "reserved_aug = naw.ReservedAug(reserved_tokens = reserved_tokens)\n",
    "augmented_texts = reserved_aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f\"src : {text}\")\n",
    "    print(f\"dst : {augmented}\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# 예제 4.16 통합 클래스 및 변환 적용 방식\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(512,512)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"datasets/images/cat.jpg\")\n",
    "transformed_image = transform(image)\n",
    "\n",
    "print(transformed_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예제 4.17 회전 및 대칭\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=30, expand=False, center=None),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=-0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예제 4.18 자르기 및 패딩\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(size=(512,512)),\n",
    "    transforms.Pad(padding=50, fill=(127,127,255), padding_mode=\"constant\")\n",
    "]\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예제 4.19 크기 조정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(512,512))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#에제 4.20 아핀 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomAffine(\n",
    "        degrees = 15, translate=(0.2,0.2),\n",
    "        scale=(0.8,1.2), shear=15\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예제 4.21 색상 변환 및 정규화\n",
    "transform = transforms.Compose([\n",
    "    transforms.ColorJitter(\n",
    "        brightness = 0.3, contrast = 0.3, saturation = 0.3, hue = 0.3\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean = [0.485, 0.456, 0.406],\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    transforms.ToPILImage()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예제 4.22 노이즈 추가\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "class IaaTransforms:\n",
    "    def __init__(self):\n",
    "        self.seq = iaa.Sequential([\n",
    "            iaa.SaltAndPepper(p=(0.03, 0.07)),\n",
    "            iaa.Rain(speed=(0.3,0.7))\n",
    "        ])\n",
    "\n",
    "    def __call__(self, images):\n",
    "        images = np.array(images)\n",
    "        augmented = self.seq.augment_image(images)\n",
    "        return Image.fromarray(augmented)\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    IaaTransforms()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예제 4.23 무작위 지우기\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=1.0,value=0), #컷아웃\n",
    "    transforms.RandomErasing(p=1.0,value=\"random\"), #무작위 지우기\n",
    "    transforms.ToPILImage()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예제 4.24 혼합\n",
    "import numpy as numpy\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class Mixup:\n",
    "    def __init__(self, target, scale, alpha=0.5, beta=0.5):\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)\n",
    "        target = self.target.resize(self.scale)\n",
    "        target = np.array(target)\n",
    "        mix_image = image*self.alpha+target*self.beta\n",
    "        return Image.fromarray(mix_image.astype(np.unit8))\n",
    "    \n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((512,512)),\n",
    "        Mixup(\n",
    "            target=Image.open(\"/home/yeeun/NLPCV/datasets/images/dog.jpg\"),\n",
    "            scale=(512,512),\n",
    "            alpha=0.5,\n",
    "            beta=0.5\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
